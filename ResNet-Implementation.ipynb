{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# needed libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "from PIL import Image\n",
    "import time\n",
    "from torch.utils.data import Dataset\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "#////ResNet implementation by Aladdin Persson\n",
    "\n",
    "#//// https://www.youtube.com/watch?v=DkNIBBBvcPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, identity_downsample=None, stride=1): #identity_downsample is the downsample of the identity block\n",
    "        super(block, self).__init__() #inherit from nn.Module\n",
    "        self.expansion = 4 #expansion is the expansion factor of the bottleneck\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)  #1x1 convolution\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels) #batch normalization\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1) #3x3 convolution\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels) #batch normalization\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, stride=1, padding=0) #1x1 convolution\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion) #batch normalization\n",
    "        self.relu = nn.ReLU() #relu activation function\n",
    "        self.identity_downsample = identity_downsample #identity downsample\n",
    "\n",
    "    def forward(self, x): #forward pass\n",
    "        identity = x #identity is the input\n",
    "\n",
    "        x = self.conv1(x) #1x1 convolution\n",
    "        x = self.bn1(x) #batch normalization\n",
    "        x = self.relu(x) #relu activation function\n",
    "        x = self.conv2(x) #3x3 convolution\n",
    "        x = self.bn2(x) #batch normalization\n",
    "        x = self.relu(x) #relu activation function\n",
    "        x = self.conv3(x) #1x1 convolution\n",
    "        x = self.bn3(x) #batch normalization\n",
    "\n",
    "        if self.identity_downsample is not None: #if identity downsample is not None\n",
    "            identity = self.identity_downsample(identity) #identity downsample\n",
    "\n",
    "        x += identity #add identity to x\n",
    "        x = self.relu(x) #relu activation function\n",
    "\n",
    "        return x #return x (output of the block)\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, image_channels, num_classes): #block is the block class, layers is the number of layers, image_channels is the number of channels in the input image, num_classes is the number of classes in the output\n",
    "        super(ResNet, self).__init__() #inherit from nn.Module\n",
    "\n",
    "        self.in_channels = 64 #in_channels is the number of channels in the input image\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3) #7x7 convolution with stride 2 and padding 3\n",
    "        self.bn1 = nn.BatchNorm2d(64) #batch normalization\n",
    "        self.relu = nn.ReLU() #relu activation function\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) #maxpool with kernel size 3, stride 2 and padding 1\n",
    "\n",
    "        # resnet\n",
    "        self.layer1 = self._make_layer(block, layers[0], out_channels=64, stride=1)\n",
    "        self.layer2 = self._make_layer(block, layers[1], out_channels=128, stride=2)\n",
    "        self.layer3 = self._make_layer(block, layers[2], out_channels=256, stride=2)\n",
    "        self.layer4 = self._make_layer(block, layers[3], out_channels=512, stride=2)  # 2048\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1)) #adaptive average pooling\n",
    "        self.fc = nn.Linear(512 * 4, num_classes) #linear layer with 2048 output channels and num_classes input channels\n",
    "\n",
    "    def forward(self, x):  #forward pass\n",
    "        x = self.conv1(x) #7x7 convolution\n",
    "        x = self.bn1(x) #batch normalization\n",
    "        x = self.relu(x) #relu activation function\n",
    "        x = self.maxpool(x) #maxpool with kernel size 3, stride 2 and padding 1\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x) #adaptive average pooling\n",
    "        x = x.reshape(x.shape[0], -1) #reshape x to a vector\n",
    "        x = self.fc(x) #linear layer with 2048 output channels and num_classes input channels\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _make_layer(self, block, num_residual_blocks, out_channels, stride): #make layer function\n",
    "        identity_downsample = None #identity_downsample is the identity downsample\n",
    "        layers = [] #layers is a list of layers\n",
    "\n",
    "        if stride != 1 or self.in_channels != out_channels * 4: #if stride is not 1 or the number of channels in the input image is not equal to the number of channels in the output image\n",
    "            identity_downsample = nn.Sequential(nn.Conv2d(self.in_channels, out_channels * 4, kernel_size=1,\n",
    "                                                          stride=stride),\n",
    "                                                nn.BatchNorm2d(out_channels * 4))\n",
    "        layers.append(block(self.in_channels, out_channels, identity_downsample, stride)) #append a block to layers with the input channels, output channels, identity downsample and stride\n",
    "        self.in_channels = out_channels * 4 #in_channels is the number of channels in the input image\n",
    "\n",
    "        for i in range(num_residual_blocks - 1):\n",
    "            layers.append(block(self.in_channels, out_channels)) #append a block to layers with the input channels, output channels and identity downsample\n",
    "\n",
    "        return nn.Sequential(*layers) #return a sequential layer with the layers in layers\n",
    "\n",
    "num_classes = int(input(\"How many classes are in your dataset\"))\n",
    "image_channels = int(input(\"How many channels are in your image\"))\n",
    "\n",
    "def ResNet50(img_channels=image_channels, num_classes=num_classes):\n",
    "    return ResNet(block, [3, 4, 6, 3], img_channels, num_classes)\n",
    "\n",
    "\n",
    "def ResNet101(img_channels=image_channels, num_classes=num_classes):\n",
    "    return ResNet(block, [3, 4, 23, 3], img_channels, num_classes)\n",
    "\n",
    "\n",
    "def ResNet152(img_channels=image_channels, num_classes=num_classes):\n",
    "    return ResNet(block, [3, 8, 36, 3], img_channels, num_classes)\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = ResNet50()\n",
    "    x = torch.rand(2, 3, 224, 224)\n",
    "    y = net(x).to(('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "    print(y.shape)\n",
    "\n",
    "\n",
    "test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the data directory, now loading the data...\n"
     ]
    }
   ],
   "source": [
    "base_dir = '/run/media/lorenz/SD 32GB L/Datasets' # Main Dataset which includes Train and Test folder\n",
    "if os.path.exists(base_dir): # Generation of train and test path, if the train and test folders exist in the main dataset and are named 'Test' and 'Train'\n",
    "    print('Found the data directory, now loading the data...')\n",
    "    train_dir = os.path.join(base_dir, 'Train')\n",
    "    test_dir = os.path.join(base_dir, 'Test')\n",
    "    # prediction directory if available\n",
    "   # predict_dir = os.path.join(base_dir, 'Prediction')\n",
    "else:\n",
    "    print('Could not find the data directory')\n",
    "    exit()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%# Data augmentation\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256]) 0\n",
      "Dataset sizes: {'Train': 8109, 'Test': 2262}\n"
     ]
    }
   ],
   "source": [
    "# augmentation function for the data\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomVerticalFlip(p=0.7),\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomHorizontalFlip(p=0.7),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "]))\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "]))\n",
    "# create predict dataset if available\n",
    "\"\"\"\n",
    "prediction_dataset = datasets.ImageFolder(predict_dir, transform=transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomVerticalFlip(p=0.7),\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomHorizontalFlip(p=0.7),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "]))\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "for image, label in train_dataset:\n",
    "    print(image.shape, label)\n",
    "    break\n",
    "\n",
    "# data loader for the data\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "# prediction loader if available\n",
    "\"\"\"\n",
    "prediction_loader = torch.utils.data.DataLoader(prediction_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\"\"\"\n",
    "# summary of the data\n",
    "dataset_sizes = {'Train': len(train_dataset), 'Test': len(test_dataset)}\n",
    "print('Dataset sizes:', dataset_sizes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# showing an example image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "imshow(image)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%# train the model\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# empty cuda cache to free up memory, if in use\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%# evaluate the model\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# choose the ResNet model to use\n",
    "net = input('Enter the network you want to use (50, 101, 152): ')\n",
    "if net == '50':\n",
    "    net = ResNet50()\n",
    "elif net == '101':\n",
    "    net = ResNet101()\n",
    "elif net == '152':\n",
    "    net = ResNet152()\n",
    "else:\n",
    "    print('Invalid network')\n",
    "    exit()\n",
    "\n",
    "# cuda if available\n",
    "net = net.to(('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train function\n",
    "# shows the progress of the training\n",
    "# after 1 epoch test on the test data\n",
    "def train_model():\n",
    "    epochs = int(input(\"Enter the number of epochs you want to train: \"))\n",
    "    train_sample_num = dataset_sizes['Train']\n",
    "    test_sample_num = dataset_sizes['Test']\n",
    "    train_cost, val_cost = [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()  # start time for the epoch\n",
    "        running_loss = 0.0  # reset the running loss\n",
    "        for i, data in enumerate(train_loader, 0):  # iterate through the training data\n",
    "            inputs, labels = data  # get the inputs and labels\n",
    "            inputs, labels = inputs.to(('cuda' if torch.cuda.is_available() else 'cpu')), labels.to(\n",
    "                ('cuda' if torch.cuda.is_available() else 'cpu'))  # move the inputs and labels to the GPU if available\n",
    "            optimizer.zero_grad()  # reset the gradients\n",
    "            outputs = net(inputs)  # get the outputs\n",
    "            loss = criterion(outputs, labels)  # get the loss\n",
    "            loss.backward()  # backpropagate the loss\n",
    "            optimizer.step()  # update the weights\n",
    "            running_loss += loss.item()  # add the loss to the running loss\n",
    "            if i % 10 == 9:  # print every 10 batches\n",
    "                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 10))  # print the loss\n",
    "                running_loss = 0.0  # reset the running loss\n",
    "        end = time.time()  # end time for the epoch\n",
    "        print('Epoch %d finished in %.2f seconds' % (epoch + 1, end - start))  # print the time taken for the epoch\n",
    "        train_cost.append(running_loss / 10)  # add the loss to the train cost list\n",
    "        with torch.no_grad():  # do not do backpropagation on the test data\n",
    "            correct = 0  # reset the correct predictions\n",
    "            total = 0  # reset the total predictions\n",
    "            for data in test_loader:  # iterate through the test data\n",
    "                images, labels = data  # get the inputs and labels\n",
    "                images, labels = images.to(('cuda' if torch.cuda.is_available() else 'cpu')), labels.to((\n",
    "                                                                                                            'cuda' if torch.cuda.is_available() else 'cpu'))  # move the inputs and labels to the GPU if available\n",
    "                outputs = net(images)  # get the outputs\n",
    "                _, predicted = torch.max(outputs.data, 1)  # get the predicted labels\n",
    "                total += labels.size(0)  # add the batch size to the total\n",
    "                correct += (predicted == labels).sum().item()  # add the correct predictions to the correct predictions\n",
    "            val_cost.append(1 - correct / total)  # add the loss to the val cost list\n",
    "            print(f'Accuracy of the network on the {len(test_dataset)} test images: %d %%' % (\n",
    "                        100 * correct / total))  # print the accuracy of the network on the test data\n",
    "    plt.plot(train_cost, label='Train')  # plot the train cost\n",
    "    plt.plot(val_cost, label='Validation')  # plot the validation cost\n",
    "    plt.legend()  # show the legend\n",
    "    plt.show()  # show the plot\n",
    "    torch.save(net.state_dict(), 'model.pth')  # save the model\n",
    "    print('Model saved')  # print the model saved message\n",
    "    return train_cost, val_cost\n",
    "\n",
    "\n",
    "train_model()  # train the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# if prediction data is available, predict the images\n",
    "\"\"\"\n",
    "def prediction(prediction_data):\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data in prediction_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(('cuda' if torch.cuda.is_available() else 'cpu')), labels.to(('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        print(f'Accuracy of the network on the {len(prediction_data)} test images: %d %%' % (100 * correct / total))\n",
    "prediction(prediction_loader)\n",
    "\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}